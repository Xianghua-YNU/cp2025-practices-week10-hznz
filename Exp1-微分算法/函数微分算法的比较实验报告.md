# 函数微分算法的比较实验报告
## 一、实验目的
1. 掌握中心差分法和Richardson外推法计算函数导数的原理和实现方法
2. 通过数值实验比较两种数值微分方法的精度特性
3. 理解不同数值微分方法的适用场景和局限性
## 二、实验原理
### 2.1 待分析函数
$$f(x) = 1 + \frac{1}{2}\tanh(2x)$$

### 2.2 中心差分法
- 计算公式：
  $$f'(x)\approx \frac{f(x+h)-f(x-h)}{2h}$$
### 2.3 Richardson外推法
- 计算公式：
  $$D_{i,j} = \frac{4^j D_{i,j-1} - D_{i-1,j-1}}{4^j - 1},\quad D_{i,0}=\frac{f(x+h_i)-f(x-h_i)}{2h_i}$$
## 三、代码实现
（此处简要说明代码实现的主要步骤和或插入代码）

def calculate_central_difference(x, f_func):
    """使用中心差分法计算数值导数"""
    dy = []
    for i in range(1, len(x)-1):
        h = x[i+1] - x[i]  # 动态计算步长
        dy.append((f_func(x[i+1]) - f_func(x[i-1])) / (2 * h))
    return np.array(dy)

def richardson_derivative_all_orders(x, f_func, h, max_order=3):
    """Richardson外推法计算不同阶数的导数值"""
    R = np.zeros((max_order + 1, max_order + 1))
    
    # 计算第一列（不同步长的中心差分）
    for i in range(max_order + 1):
        hi = h / (2**i)
        R[i, 0] = (f_func(x + hi) - f_func(x - hi)) / (2 * hi)
    
    # Richardson外推填充表
    for j in range(1, max_order + 1):
        for i in range(max_order - j + 1):
            R[i, j] = (4**j * R[i+1, j-1] - R[i, j-1]) / (4**j - 1)
    
    return [R[0, j] for j in range(1, max_order + 1)]
## 四、实验结果与分析
### 4.1 导数计算结果对比
![屏幕截图 2025-05-02 122953](https://github.com/user-attachments/assets/d47c25b7-f590-477e-b87e-4f79b8b0584c)


### 4.2 误差分析 
#### 4.2.1 中心差分法误差分析
![屏幕截图 2025-05-02 123005](https://github.com/user-attachments/assets/560a6216-17be-4a35-9d54-1205fce70cf6)
#### 4.2.2 Richardson外推法误差分析
![屏幕截图 2025-05-02 123012](https://github.com/user-attachments/assets/92d81955-2dce-4681-b6fa-732b42b9be54)

## 五、实验讨论
### 5.1 两种方法的优缺点分析
1. 中心差分法
   - 优点：实现简单，计算速度快，适用于大多数光滑函数。
   - 缺点：误差为 O(h**2)，步长过小会因舍入误差导致精度下降。
2. Richardson外推法
   - 优点：通过多阶外推显著提高精度（例如 O(h**4) 或更高），对步长敏感性低。
   - 缺点：计算复杂，需要多次调用函数，内存占用较高。
